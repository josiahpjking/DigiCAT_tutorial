<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>DigiCAT Tutorials - 4. Counterfactual Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-hand-o-right')) {
    f.classList.add('fa-hand-o-down')
    f.classList.remove('fa-hand-o-right')
} else {
    f.classList.add('fa-hand-o-right')
    f.classList.remove('fa-hand-o-down')
}
}
</script>

<script src="https://kit.fontawesome.com/120b08a6f5.js" crossorigin="anonymous"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04_cfmethod.html">4. Counterfactual Methods</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">DigiCAT Tutorials</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DigiCAT Tutorial Pages</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_howto_digicat.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. The DigiCAT Tool</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_introcf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Introduction to Counterfactual Analysis</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_choosecf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Choosing a Counterfactual Analysis Approach</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_cfmethod.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">4. Counterfactual Methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Missing Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_survey.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Complex Survey Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_further.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements &amp; Further reading</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-potential-outcomes-framework" id="toc-the-potential-outcomes-framework" class="nav-link active" data-scroll-target="#the-potential-outcomes-framework">The potential outcomes framework</a></li>
  <li><a href="#propensity-score-matching" id="toc-propensity-score-matching" class="nav-link" data-scroll-target="#propensity-score-matching">Propensity score matching</a>
  <ul class="collapse">
  <li><a href="#description-of-psm" id="toc-description-of-psm" class="nav-link" data-scroll-target="#description-of-psm">Description of PSM</a></li>
  <li><a href="#steps-in-psm" id="toc-steps-in-psm" class="nav-link" data-scroll-target="#steps-in-psm">Steps in PSM</a></li>
  <li><a href="#selecting-matching-variables" id="toc-selecting-matching-variables" class="nav-link" data-scroll-target="#selecting-matching-variables">Selecting Matching Variables</a></li>
  <li><a href="#propensity-score-specification-and-estimation" id="toc-propensity-score-specification-and-estimation" class="nav-link" data-scroll-target="#propensity-score-specification-and-estimation">Propensity score specification and estimation</a></li>
  <li><a href="#logistic-and-probit-regression" id="toc-logistic-and-probit-regression" class="nav-link" data-scroll-target="#logistic-and-probit-regression">Logistic and probit regression</a></li>
  <li><a href="#nearest-neighbour-11-matching" id="toc-nearest-neighbour-11-matching" class="nav-link" data-scroll-target="#nearest-neighbour-11-matching">Nearest neighbour 1:1 matching</a></li>
  <li><a href="#nearest-neighbour-k1-matching" id="toc-nearest-neighbour-k1-matching" class="nav-link" data-scroll-target="#nearest-neighbour-k1-matching">Nearest neighbour K:1 matching</a></li>
  <li><a href="#optimal-matching" id="toc-optimal-matching" class="nav-link" data-scroll-target="#optimal-matching">Optimal Matching</a></li>
  <li><a href="#balance-checking" id="toc-balance-checking" class="nav-link" data-scroll-target="#balance-checking">Balance Checking</a></li>
  <li><a href="#outcome-model" id="toc-outcome-model" class="nav-link" data-scroll-target="#outcome-model">Outcome model</a></li>
  </ul></li>
  <li><a href="#iptw" id="toc-iptw" class="nav-link" data-scroll-target="#iptw">IPTW</a></li>
  <li><a href="#nbp" id="toc-nbp" class="nav-link" data-scroll-target="#nbp">NBP</a>
  <ul class="collapse">
  <li><a href="#conceptually-how-does-nonbipartite-matching-work" id="toc-conceptually-how-does-nonbipartite-matching-work" class="nav-link" data-scroll-target="#conceptually-how-does-nonbipartite-matching-work">Conceptually, how does nonbipartite matching work?</a></li>
  <li><a href="#propensity-model-estimation" id="toc-propensity-model-estimation" class="nav-link" data-scroll-target="#propensity-model-estimation">Propensity model estimation</a></li>
  <li><a href="#optimal-matching-1" id="toc-optimal-matching-1" class="nav-link" data-scroll-target="#optimal-matching-1">Optimal matching</a></li>
  <li><a href="#outcome-model-1" id="toc-outcome-model-1" class="nav-link" data-scroll-target="#outcome-model-1">Outcome model</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">4. Counterfactual Methods</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="the-potential-outcomes-framework" class="level2">
<h2 class="anchored" data-anchor-id="the-potential-outcomes-framework">The potential outcomes framework</h2>
<p>Counterfactual analysis is based on what is known as the ‘potential outcomes’ framework which was formalised by Rubin. It is based on the notion that for each unit exposed to a treatment W (Wi = 1) there is a potential outcome (Wi = 0) where they weren’t exposed to that treatment. It is assumed that each unit assigned to the treated and control groups have ‘potential outcomes’ in both states but only one of these states is observed. Within the potential outcomes framework, a causal effect of a binary treatment is defined as the difference between these potential outcomes. Counterfactual analysis methods have to solve the problem that only one of these potential outcomes is observed for each individual.</p>
<p>The methods in DigiCAT are based on the potential outcomes framework and therefore carry certain assumptions inherited from the framework. A major one is the stable unit treatment assumption (SUVTA) which means that the potential outcomes for any unit does not depend on the treatment assignment of any other units. This means that there is no interference between units. Another important one is that there are no unmeasured/unmodelled confounders that are associated with the potential outcomes and with treatment assignment. Other assumptions associated with specific counterfactual analysis workflows are discussed with each method.</p>
</section>
<section id="propensity-score-matching" class="level2">
<h2 class="anchored" data-anchor-id="propensity-score-matching">Propensity score matching</h2>
<section id="description-of-psm" class="level3">
<h3 class="anchored" data-anchor-id="description-of-psm">Description of PSM</h3>
</section>
<section id="steps-in-psm" class="level3">
<h3 class="anchored" data-anchor-id="steps-in-psm">Steps in PSM</h3>
<p>The main steps in PSM are to: 1) decide on which matching variables to include 2) fit a propensity model including these variables to estimate propensity scores (reflecting their propensity to experience a treatment variable) each individual in the sample 3) match treated individuals and control individuals with similar propensity scores 4) fit an outcome model using the matched data.</p>
</section>
<section id="selecting-matching-variables" class="level3">
<h3 class="anchored" data-anchor-id="selecting-matching-variables">Selecting Matching Variables</h3>
<p>In order to successfully address confounding with PSM it is necessary to identify and include measures of all relevant confounders in the propensity model. It is also necessary to specify the correct functional form of relations between the matching variables and the treatment variable; an issue discussed in more detail later. Confounders are variables that are common causes of both treatment assignment and the outcome. For example, when aiming to estimate the impact of physical activity on mental health, a person’s gender might be a confounding factor as it might impact both physical activity levels and mental health outcomes. These confounders should be chosen based on theory and past research. There is no real way to test that all relevant confounders have been identified and measured, therefore, there is a strong reliance on subject matter knowledge when choosing matching variables. Drawing causal diagrams can help to lay out the hypothesised causal relations between treatment, confounders and outcome. Arguments have also been made for including variables in the propensity model that are related only to the outcome (not treatment) variable since this can increase power to detect the treatment effect. On the other hand, it has been shown that including variables related only to the treatment variable (not the outcome variable) can reduce power. It is critical to not include variables that might have been impacted by the outcome variable as this can induce seriously distort the treatment effects. For this reason, researchers often limit the selection of matching variables to those that occurred (or were measured) prior to the treatment. In practice, it may be difficult to identify and to have measures available of all possible relevant confounders, therefore, researchers tend to select a large number of potential confounders.</p>
</section>
<section id="propensity-score-specification-and-estimation" class="level3">
<h3 class="anchored" data-anchor-id="propensity-score-specification-and-estimation">Propensity score specification and estimation</h3>
<p>Propensity score models can and have been estimated using a wide variety of approaches. This could include (regularised) regression approaches, machine learning tree-based methods, such as CART, and ensemble tree-based methods such as random forest or gradient boosted machines. Other machine learning techniques such as support vector machines and neural networks are also possible choices. There are pros and cons to different methods and DigiCAT provides an implementation of a selection of complementary methods. Logistic regression is provided for its high interpretability and quick computation. Two tree-based machine learning methods: random forest and gradient boosted machines are provided because they have good flexibility for approximating complex relations between matching variables and treatments and because previous research has shown that they often achieve better prediction than logistic regression. Each approach is described in more detail below.</p>
</section>
<section id="logistic-and-probit-regression" class="level3">
<h3 class="anchored" data-anchor-id="logistic-and-probit-regression">Logistic and probit regression</h3>
<p>Logistic regression has historically been by far the most popular method of estimating propensity scores. It and probit regression are method that can estimate the associations between a set of predictors and a binary (0 vs 1) outcome variable. This makes them suitable models for estimating propensity scores for binary treatments. In a simple logistic regression with only one predictor, the probability that <span class="math inline">\(Y=1\)</span>, which we could denote <span class="math inline">\(P(y_i)\)</span>, is predicted from a matching variables, which we could denote <span class="math inline">\(X_1\)</span>, using the formula:</p>
<p><span class="math display">\[
P(y_i) = \frac{1}{1+e^{-(b_0 + b_1X_1)}}
\]</span></p>
<p>e refers to the exponential function and <span class="math inline">\(b_0+b_1 X_{1}\)</span> forms a linear combination with a constant <span class="math inline">\(b_0\)</span> and the coefficient <span class="math inline">\(b_1\)</span> which captures the effect of the predictor <span class="math inline">\(X_1\)</span>. This then generalises to a multiple logistic regression that can include many matching variables and their interactions.:</p>
<p><span class="math display">\[
P(y_i) = \frac{1}{1+e^{-(b_0 + b_1X_1 + b_2X_2 + ... + b_kX_k)}}
\]</span></p>
<p>Each <span class="math inline">\(b\)</span> coefficient captures the effect of one predictor which in the context of propensity score analysis represents the effect of each matching variable on the treatment, The model can be estimated using maximum likelihood estimation. The individual b coefficients are typically not of great interest in a propensity analysis context. Instead of key interest is the propensity score. For each individual, propensity scores are the scores predicted by the model based on the estimated b coefficients. That is the predicted <span class="math inline">\(P(y_i)\)</span> scores represented the predicted probability of having received the treatment. It is these scores that are used in subsequent stages of propensity score analysis for matching or to derive weights in IPTW.</p>
<p>Estimating propensity scores using probit regression is very similar to logistic regression…. In DigiCAT…</p>
<p>TODO</p>
<ul>
<li>Logistic regression</li>
<li>Random forest</li>
<li>Gradient boosted machines /generalised boosted modeling</li>
<li>Intro to GBM – what is it?</li>
<li>Why GBM for PS estimation</li>
<li>Tuning</li>
<li>Calibrated probabilities</li>
</ul>
<p>There are different possible ways to use the propensity scores estimated in the previous step to match treated and control cases. The goal is to try and pair treated and control units that are highly similar in their propensity scores. Matching methods differ in things like what type of algorithm is used (‘greedy’ or ‘optimal’ matching), whether matching happens with or without replacement (I.e., whether a control be matched to multiple cases), the matching ratio (e.g., 2 controls to 1 treated unit, 3:1), the order in which treated and control units are matched, and whether calipers are applied, meaning that matches are only made if treated and control cases fall within a defined threshold of ‘similarity’. Taken together, there are a very large number of options for how to match treated and control cases!</p>
<p>In DigiCAT we offer a set of methods that have generally been shown to perform well in terms of important outcomes such as giving the least biased estimates of treatment effects. These are described in turn.</p>
</section>
<section id="nearest-neighbour-11-matching" class="level3">
<h3 class="anchored" data-anchor-id="nearest-neighbour-11-matching">Nearest neighbour 1:1 matching</h3>
<p>Nearest neighbour matching refers to a type of matching method that uses what is called ‘greedy matching’. In this method, a treated case is selected and the most similar control unit is matched with it. If there are multiple equally similar control units then one of them is selected at random. Then, another treated case is selected and the most similar control unit to it and so on and so forth until no more matches are possible. The simplest form of nearest neighbour matching uses matching without replacement whereby once a control unit has been matched to a treated unit, it is no longer available for matching to further treated units.</p>
<p>Nearest neighbour matching is also used with ‘calipers’ applied. This restricts matches only to treated and control units that are within a specified level of similarity to each other. This restriction is referred to as the ‘caliper distance’ and it helps to control the amount of ‘imbalance’ allowed between the treated and control units after matching. When calipers are applied, not all treated units will necessarily find a match; for some, there may not be any control units available that are sufficiently similar. In general, studies have found that using a caliper with nearest neighbour matching is beneficial for getting less biases treatment effect estimates (e.g., Austin, 2014). However, others have cautioned against using too strict calipers as these can have detrimental effects. Specifically, it can change the interpretation of the treatment effect from the effect of the treatment on the treated to the ‘effect of the treatment on the treated who have similar-enough controls’. The treated who have similar-enough controls might not be very representative of the underlying relevant population.</p>
<p>There has been some discussion and disagreement about the best caliper width to use. Most recommendations have been based on defining a threshold on the scale of the log-odds of the propensity score, I.e., the linear predictor of the treatment taken from the logistic regression used to estimate the propensity scores. For example, one suggestion has been to take the 0.25 standard deviations of the log-odds of the propensity score, while others have argued for 0.20 standard deviations on this scale. The reality is that the right caliper width depends to some extent on the data and the willingness of the researchers to accept some bias in the estimate of the treatment effect for the sake of having ‘enough’ matches. This is because the stricter the caliper width is, the more difficult it is to find matches that meet the matching criteria.</p>
<p>[XXX brief 1-2 lines on choosing caliper distance]</p>
<p>In DigiCAT nearest neighbour matching is chosen by selecting the ‘X’ option on the ‘X’ screen. This implements nearest neighbour matching with…</p>
</section>
<section id="nearest-neighbour-k1-matching" class="level3">
<h3 class="anchored" data-anchor-id="nearest-neighbour-k1-matching">Nearest neighbour K:1 matching</h3>
<p>Nearest neighbour k:1 matching (also known as ‘many to one’ matching) is when each treated case is matched to multiple control cases. The ‘k’ refers to the number of controls that get matched to each treated unit. K:1 matching is done to make more use of the available sample as compared to 1:1 matching. In 1:1 matching if a treatment is rare (e.g., 50 out of a sample of 1000 experience it) then 1:1 matching leads to a lot of the sample not being used on the analysis (in this case only 100 out of the 1000 would be used at most).</p>
<p>It is important to note that matching more controls to each treated unit should not logically give a more accurate estimate of the effect of treatment. Rather, the main benefit of k:1 matching is that it can increase the precision of the estimate of the treatment effect.</p>
<p>The availability of k:1 matching raises the question of how many controls to match to each treated unit. Austin (2010) frame this decision in terms of a variance-bias trade-off. Specifically they point out that if you increase the the number of control units you can increase the matched sample size and thereby the precision (this is the ‘variance’ part of the trade-off). However, this likely means that you have to match control units that are less similar to their corresponding treated units. This could make the estimate of the treatment effect less accurate (the ‘bias’ part of the trade-off). They found using a simulation study that 1:1 nearest neighbour matching gave the most accurate treatment effects. Balancing various considerations they recommended that for most researchers, 1;1 or 2:1 matching (I.e., matching each treated unit to either 1 or 2 control units) is likely to the best option.</p>
<p>DigiCAT offers k:1 nearest neighbour matching. A slider on the XX page allows you to select the number of controls you wish to match to each treated unit. Using k:1 matching might make sense if your treatment variable is quite rare within your sample. If you choose k:1 matching, we recommend you also try 1:1 matching and compare the results to see if your conclusions are similar.</p>
</section>
<section id="optimal-matching" class="level3">
<h3 class="anchored" data-anchor-id="optimal-matching">Optimal Matching</h3>
<p>Optimal matching is a matching algorithm which creates matches based on the criterion of minimising the average dis-similarity within pairs of treated and control units [not much more to say about this?]</p>
</section>
<section id="balance-checking" class="level3">
<h3 class="anchored" data-anchor-id="balance-checking">Balance Checking</h3>
<p>Balance checking refers to assessing whether after matching on the propensity score, treated and control units are sufficiently similar in their matching variable distributions. A large variety of methods of checking balance have been suggested. These include methods for looking at overall balance (I.e., a summary measure of balance across all matching variables) and methods for looking at balance in the individual covariates. As regards, individual covariates, originally this was done using statistical tests (e.g.&nbsp;a t-test or chi-square test); however, nowadays this is generally avoided since these tests depend on sample size. Instead, measures such as standardised mean differences (SMDs) are used to quantify bias, complemented with graphical displays. Previous studies have discussed potential SMD thresholds to decide whether balance is suitably met, with different authors proposing |.05|, |.10|, and |.25|. It has also been noted that lower thresholds are needed for binary matching variables to be equivalent to continuous variables |.1| for binary variables is roughly equivalent to |.25| for continuous variables). However, which threshold a user prefers depends on what level of imbalance a user is willing to accept (also see the discussion on calipers). Irrespective, for transparency and to aid the interpretation of findings, it is good practice to present the SMDs for the covariates when writing up. Where there is some imbalance between the groups, adjusting for the matching variables in the outcome model can be helpful for addressing any bias due to this (see ‘outcome model’ section).</p>
<p>In terms of overall balance measures… [briefly discuss but focus on what’s implemented in DigiCAT] Both SMDs and graphical displays are implemented within DigiCAT and are provided after fitting the propensity model and implementing the matching. This allows users to inspect the quality of matches before proceeding to the outcome model. If the balance is poor, you may consider using a different method to try and get better balance. For example, you could try a different method of estimating propensity scores, switch from k:1 to 1:1 matching, or switch between nearest neighbour or optimal matching.</p>
</section>
<section id="outcome-model" class="level3">
<h3 class="anchored" data-anchor-id="outcome-model">Outcome model</h3>
<p>The final step in the PSM analysis workflow is fitting the outcome model. This is actually often much simpler than estimating the propensity model. It involves fitting a linear regression model to the now-matched data with the treatment indicator as a predictor. There are also good arguments for including the matching variables in this model too.</p>
</section>
</section>
<section id="iptw" class="level2">
<h2 class="anchored" data-anchor-id="iptw">IPTW</h2>
<p>Inverse propensity of treatment weighting (IPTW) is a counterfactual analysis approach that attempts to balance treated and control units through the use of weights. The first step is identical to propensity matching and involves fitting a propensity model to get propensity scores. In this model, the treatment variable is predicted by the matching variables in a model such as a random forest or logistic regression. Those scores are then transformed to provide weights. The balance of the weighted groups is then checked. Finally, the weights are used in a weighted regression. These steps are discussed in more detail below.</p>
<ul>
<li>Steps in IPTW</li>
<li>Estimating weights for ATT</li>
<li>Estimating weights for ATE</li>
<li>Weight stabilisation/truncation (if needed)</li>
<li>Balance checking</li>
<li>Weighted outcome model</li>
<li>[will follow very similar structure to PSM]</li>
</ul>
</section>
<section id="nbp" class="level2">
<h2 class="anchored" data-anchor-id="nbp">NBP</h2>
<p>The majority of matching methods available, including those described in DigiCAT, are ‘bipartite’, which is fitting for designs with only two treatment options (one treatment group and one control group). However, in practice you may encounter a scenario in which participants may receive multiple different treatments. For example, participants may adhere to one of several treatments to stop smoking or drinking – standard care, self-help and counselling-guided intervention, interactive computer programs, or a combination of these. Another scenario may be if we are investigating the number of hours of social media consumption on anxiety, for example, or the number of hours of sleep on wellbeing – in which case, the treatment is on a continuous scale, rather than dichotomous . In order to determine causal inference in such situations, nonbipartite matching methods have been suggested in place of bipartite methods.</p>
<section id="conceptually-how-does-nonbipartite-matching-work" class="level3">
<h3 class="anchored" data-anchor-id="conceptually-how-does-nonbipartite-matching-work">Conceptually, how does nonbipartite matching work?</h3>
<p>In the distance matrix tabulated below, we can imagine 6 different groups (termed ‘nodes’, in graph theory) that may be matched with one another. Some groups, such as 3 and 4, cannot be matched with one another, as the distance between them is an ‘infinite distance’.</p>
<p>Optimal matching would aim to create a matching consisting of 3 pairs, which the overall smallest total distance. Thus, matching result for the example below would be pairs of 1 and 6, 2 and 4, and 3 and 5, which would give a total overall distance of 30, the smallest achievable (10 + 10 + 10). Although, for instance, nodes 1 and 2 have an even smaller distance (of just 1), this would mean the remaining pairs to be matched would yield a greater overall distance, as node 6 would be left to match either with 4 or 5 (note it cannot be matched with 3 as it is of infinite distance), which have greater distances (100), and so the overall distance would not be the smallest possible.</p>
<p>This is demonstrative of where optimal matching is superior to greedy matching, which would match nodes by proximity, but not consider overall distance and not yield the global optimal solution. In this instance, the 6 groups cannot be clustered into two, and therefore a nonbipartite algorithm should be used in place of bipartite algorithms.</p>
<table class="table">
<thead>
<tr class="header">
<th>Node</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(\infty\)</span></td>
<td>1</td>
<td><span class="math inline">\(\infty\)</span></td>
<td>2</td>
<td><span class="math inline">\(\infty\)</span></td>
<td>10</td>
</tr>
<tr class="even">
<td>2</td>
<td>1</td>
<td><span class="math inline">\(\infty\)</span></td>
<td>2</td>
<td>10</td>
<td>100</td>
<td><span class="math inline">\(\infty\)</span></td>
</tr>
<tr class="odd">
<td>3</td>
<td><span class="math inline">\(\infty\)</span></td>
<td>2</td>
<td><span class="math inline">\(\infty\)</span></td>
<td><span class="math inline">\(\infty\)</span></td>
<td>10</td>
<td><span class="math inline">\(\infty\)</span></td>
</tr>
<tr class="even">
<td>4</td>
<td>2</td>
<td>10</td>
<td><span class="math inline">\(\infty\)</span></td>
<td><span class="math inline">\(\infty\)</span></td>
<td>30</td>
<td>100</td>
</tr>
<tr class="odd">
<td>5</td>
<td><span class="math inline">\(\infty\)</span></td>
<td>100</td>
<td>10</td>
<td>30</td>
<td><span class="math inline">\(\infty\)</span></td>
<td>100</td>
</tr>
<tr class="even">
<td>6</td>
<td>10</td>
<td><span class="math inline">\(\infty\)</span></td>
<td><span class="math inline">\(\infty\)</span></td>
<td>100</td>
<td>100</td>
<td><span class="math inline">\(\infty\)</span></td>
</tr>
</tbody>
</table>
<p>Although nonbipartite matching can also be used with multiple unordered groups and time varying covariates, in DigiCAT it currently focuses on matching with multiple ordinal dose groups, specifically, and should not be interpreted as otherwise unless stated. In this scenario, the general steps would be as follows: first, generate propensity scores through an ordinal logit model, and then leverage these propensity scores to measure distances between participants. Following calculation of the distances, optimal nonbipartite matching would be performed to match participants possessing similar pre-treatment characteristics. Note, it is assumed that matching variables are the only variables that influence treatment assignment.</p>
</section>
<section id="propensity-model-estimation" class="level3">
<h3 class="anchored" data-anchor-id="propensity-model-estimation">Propensity model estimation</h3>
<section id="ordinal-logistic-regression" class="level4">
<h4 class="anchored" data-anchor-id="ordinal-logistic-regression">Ordinal logistic regression</h4>
</section>
</section>
<section id="optimal-matching-1" class="level3">
<h3 class="anchored" data-anchor-id="optimal-matching-1">Optimal matching</h3>
</section>
<section id="outcome-model-1" class="level3">
<h3 class="anchored" data-anchor-id="outcome-model-1">Outcome model</h3>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>